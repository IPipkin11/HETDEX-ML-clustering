{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy\n",
    "import matplotlib\n",
    "import matplotlib.path as mpltPath\n",
    "import scipy.ndimage\n",
    "\n",
    "import astropy.io.fits as pyfits\n",
    "import astropy.table\n",
    "\n",
    "import astropy.wcs\n",
    "import pandas\n",
    "import argparse\n",
    "import logging\n",
    "import ephem\n",
    "import astropy.coordinates\n",
    "import astropy.units as u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bufferzone = 3\n",
    "\n",
    "def make_round_kernel(size):\n",
    "    k = numpy.zeros((2 * size + 1, 2 * size + 1), dtype=numpy.float)\n",
    "\n",
    "    _iy, _ix = numpy.indices(k.shape, dtype=numpy.float)\n",
    "    _ix -= size\n",
    "    _iy -= size\n",
    "    _radius = numpy.hypot(_ix, _iy)\n",
    "    k[_radius <= size] = 1.\n",
    "\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_polygons(polygon_list, image, wcs, edgewidth=1, deadspace=0, skysize=1.,\n",
    "                     generate_check_images=False):\n",
    "    logger = logging.getLogger(\"MeasurePolygon\")\n",
    "    bufferzone = edgewidth + 2\n",
    "\n",
    "    pixelscale = astropy.wcs.utils.proj_plane_pixel_scales(wcs)\n",
    "    print(pixelscale)\n",
    "\n",
    "    dead_pixels = int(numpy.ceil(deadspace / (pixelscale[0] * 3600)))\n",
    "    sky_pixels = int(numpy.ceil(skysize / (pixelscale[0] * 3600)))\n",
    "\n",
    "    bufferzone = dead_pixels + sky_pixels + 2\n",
    "\n",
    "    iy, ix = numpy.indices(image.shape)\n",
    "    # print(iy)\n",
    "    # print(ix)\n",
    "    # print(ix.ravel())\n",
    "    index_xy = numpy.hstack((ix.reshape((-1, 1)), iy.reshape((-1, 1))))\n",
    "    # print(index_xy)\n",
    "    # print(index_xy.shape)\n",
    "\n",
    "    # edge_kernel = numpy.ones((2*edgewidth+1, 2*edgewidth+1))\n",
    "    # dead_kernel = numpy.ones((2*dead_pixels+1, 2*dead_pixels+1))\n",
    "    # sky_kernel = numpy.ones((2*sky_pixels+1, 2*sky_pixels+1))\n",
    "\n",
    "    dead_kernel = make_round_kernel(dead_pixels)\n",
    "    sky_kernel = make_round_kernel(sky_pixels)\n",
    "\n",
    "    pyfits.PrimaryHDU(data=dead_kernel).writeto(\"poly2flux_kernel_dead.fits\", overwrite=True)\n",
    "    pyfits.PrimaryHDU(data=sky_kernel).writeto(\"poly2flux_kernel_sky.fits\", overwrite=True)\n",
    "\n",
    "    polygon_data = []\n",
    "\n",
    "    check_sources = [pyfits.PrimaryHDU()]\n",
    "    check_dead = [pyfits.PrimaryHDU()]\n",
    "    check_sky = [pyfits.PrimaryHDU()]\n",
    "    check_source_sky = [pyfits.PrimaryHDU()]\n",
    "\n",
    "    polygon_catalog = pandas.DataFrame(\n",
    "        columns=['center_x', 'center_y',\n",
    "                 'src_flux', 'src_area',\n",
    "                 'sky_median', 'sky_mean', 'sky_std', 'sky_area', 'sky_var',\n",
    "                 ],\n",
    "    )\n",
    "    for ipoly, polygon in enumerate(polygon_list):\n",
    "\n",
    "        # sys.stdout.write(\".\")\n",
    "        # sys.stdout.flush()\n",
    "        logger.debug(\"working on polygon %d of %d\" % (ipoly + 1, len(polygon_list)))\n",
    "\n",
    "        # first, convert ra/dec to x/y\n",
    "        xy = wcs.all_world2pix(polygon, 0)\n",
    "        # print(xy)\n",
    "\n",
    "        #\n",
    "        # to speed things up, don't work on the whole image, but\n",
    "        # rather only on the little area around and including the polygon\n",
    "        #\n",
    "        min_xy = numpy.floor(numpy.min(xy, axis=0)).astype(numpy.int) - [bufferzone, bufferzone]\n",
    "        min_xy[min_xy < 0] = 0\n",
    "        max_xy = numpy.ceil(numpy.max(xy, axis=0)).astype(numpy.int) + [bufferzone, bufferzone]\n",
    "        # print(min_xy, max_xy)\n",
    "\n",
    "        max_x, max_y = max_xy[0], max_xy[1]\n",
    "        min_x, min_y = min_xy[0], min_xy[1]\n",
    "\n",
    "        # cutout the area with points in the region\n",
    "        poly_ix = ix[min_y:max_y + 1, min_x:max_x + 1]\n",
    "        poly_iy = iy[min_y:max_y + 1, min_x:max_x + 1]\n",
    "        poly_xy = numpy.hstack((poly_ix.reshape((-1, 1)), poly_iy.reshape((-1, 1))))\n",
    "        # print(poly_xy.shape)\n",
    "        # print(poly_xy)\n",
    "\n",
    "        # use some matplotlib magic to figure out which points are inside the polygon\n",
    "        path = mpltPath.Path(xy)\n",
    "        inside2 = path.contains_points(poly_xy)\n",
    "        inside2d = inside2.reshape(poly_ix.shape)\n",
    "        # print(inside2d.shape)\n",
    "\n",
    "        # to get at the border of the polygon, convolve the mask with a small filter\n",
    "        dead_widened = scipy.ndimage.convolve(inside2d.astype(numpy.int), dead_kernel,\n",
    "                                              mode='constant', cval=0)\n",
    "        sky_widened = scipy.ndimage.convolve(dead_widened.astype(numpy.int), sky_kernel,\n",
    "                                             mode='constant', cval=0)\n",
    "\n",
    "        edge_only_pixels = (dead_widened > 0) & (~inside2d)\n",
    "        sky_only_pixels = (sky_widened > 0) & ~(dead_widened > 0)\n",
    "        dead_only_pixels = (dead_widened > 0) & (~inside2d)\n",
    "        image_region = image[min_y:max_y + 1, min_x:max_x + 1]\n",
    "\n",
    "        # generate the check images\n",
    "        # mask_image_region = mask_image[ min_y:max_y+1, min_x:max_x+1 ]\n",
    "        # mask_image_region[inside2d] = image_region[inside2d]\n",
    "\n",
    "        # edge_image_region = edge_image[ min_y:max_y+1, min_x:max_x+1 ]\n",
    "        # edge_image_region[edge_only_pixels] += 1\n",
    "\n",
    "        n_pixels = numpy.sum(inside2)\n",
    "\n",
    "        # set some default values in case things go wrong down the line\n",
    "        total_flux = -1\n",
    "        center_x = -1\n",
    "        center_y = -1\n",
    "        edge_mean = edge_median = edge_area = -1\n",
    "        sky_mean = sky_median = sky_area = sky_std = sky_var = -1\n",
    "\n",
    "        if (n_pixels >= 1):\n",
    "            total_flux = numpy.sum(image_region[inside2d])\n",
    "\n",
    "            # calculate mean position of points inside polygon\n",
    "            center_x = numpy.mean(poly_ix[inside2d])\n",
    "            center_y = numpy.mean(poly_iy[inside2d])\n",
    "\n",
    "            edge_mean = numpy.nanmean(image_region[edge_only_pixels])\n",
    "            edge_median = numpy.nanmedian(image_region[edge_only_pixels])\n",
    "            edge_area = numpy.sum(edge_only_pixels)\n",
    "\n",
    "            edge_mean = numpy.nanmean(image_region[sky_only_pixels])\n",
    "            edge_median = numpy.nanmedian(image_region[sky_only_pixels])\n",
    "            edge_area = numpy.sum(sky_only_pixels)\n",
    "\n",
    "            sky_pixels = image_region[sky_only_pixels]\n",
    "            good = numpy.isfinite(sky_pixels)\n",
    "            for iteration in range(3):\n",
    "                _stats = numpy.nanpercentile(sky_pixels[good], [16, 50, 84])\n",
    "                _median = _stats[1]\n",
    "                _sigma = 0.5 * (_stats[2] - _stats[0])\n",
    "                outlier = (sky_pixels > (_median + 3 * _sigma)) | (sky_pixels < (_median - 3 * _sigma))\n",
    "                good[outlier] = False\n",
    "\n",
    "            sky_mean = numpy.nanmean(sky_pixels[good])\n",
    "            sky_median = numpy.nanmedian(sky_pixels[good])\n",
    "            sky_std = numpy.nanstd(sky_pixels[good])\n",
    "            sky_var = numpy.nanvar(sky_pixels[good])\n",
    "            sky_area = numpy.sum(sky_only_pixels)\n",
    "\n",
    "            polygon_data.append([n_pixels, total_flux, center_x, center_y, edge_mean, edge_median, edge_area])\n",
    "\n",
    "        polygon_catalog.loc[ipoly, 'center_x'] = center_x\n",
    "        polygon_catalog.loc[ipoly, 'center_y'] = center_y\n",
    "        polygon_catalog.loc[ipoly, 'src_flux'] = total_flux\n",
    "        polygon_catalog.loc[ipoly, 'src_area'] = numpy.sum(inside2d)\n",
    "        polygon_catalog.loc[ipoly, 'sky_median'] = sky_median\n",
    "        polygon_catalog.loc[ipoly, 'sky_mean'] = sky_mean\n",
    "        polygon_catalog.loc[ipoly, 'sky_std'] = sky_std\n",
    "        polygon_catalog.loc[ipoly, 'sky_area'] = sky_area\n",
    "        polygon_catalog.loc[ipoly, 'sky_var'] = sky_var\n",
    "\n",
    "        # continue\n",
    "\n",
    "        # do not use this doe, it's slow as hell\n",
    "        # path = mpltPath.Path(xy)\n",
    "        # inside2 = path.contains_points(index_xy)\n",
    "        # inside2d = inside2.reshape(image.shape)\n",
    "\n",
    "        # mask_image[inside2d] = 1\n",
    "\n",
    "        if (generate_check_images):\n",
    "            img = image_region.copy()\n",
    "            img[~inside2d] = numpy.NaN\n",
    "\n",
    "            dead = image_region.copy()\n",
    "            dead[~dead_only_pixels] = numpy.NaN\n",
    "\n",
    "            sky = image_region.copy()\n",
    "            sky[~sky_only_pixels] = numpy.NaN\n",
    "\n",
    "            source_sky = image_region.copy()\n",
    "            source_sky[~sky_only_pixels & ~inside2d] = numpy.NaN\n",
    "\n",
    "            check_sources.append(pyfits.ImageHDU(img))\n",
    "            check_dead.append(pyfits.ImageHDU(dead))\n",
    "            check_sky.append(pyfits.ImageHDU(sky))\n",
    "            check_source_sky.append(pyfits.ImageHDU(source_sky))\n",
    "\n",
    "    polygon_data = numpy.array(polygon_data)\n",
    "\n",
    "    polygon_catalog['flux_bgsub'] = polygon_catalog['src_flux'] - polygon_catalog['src_area'] * polygon_catalog[\n",
    "        'sky_median']\n",
    "\n",
    "    if (generate_check_images):\n",
    "        return polygon_catalog, (check_sources, check_dead, check_sky, check_source_sky)\n",
    "    return polygon_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_polygons_from_ds9_region_file(fn):\n",
    "    #\n",
    "    # Now read the region file\n",
    "    #\n",
    "    src_polygons = []\n",
    "    lines = []\n",
    "    with open(fn, \"r\") as regfile:\n",
    "        lines = regfile.readlines()\n",
    "        logger.info(\"Read %d lines\" % (len(lines)))\n",
    "\n",
    "    for line in lines:\n",
    "        if (not line.startswith(\"polygon(\")):\n",
    "            # don't do anything\n",
    "            continue\n",
    "\n",
    "        coordinates_text = line.split(\"polygon(\")[1].split(\")\")[0]\n",
    "        coordinates = coordinates_text.split(\",\")\n",
    "        # print(coordinates)\n",
    "\n",
    "        try:\n",
    "            coordinates2 = [float(c) for c in coordinates]\n",
    "            coordinates_radec = numpy.array(coordinates2).reshape((-1, 2))\n",
    "        except ValueError:\n",
    "            # this most likely means that coordinates are in H:M:S format\n",
    "            # easiest to use ephem to convert them to degrees\n",
    "            logger.debug(\"Found coordinates in H:M:S system\")\n",
    "            coordinates_radec = []\n",
    "            for c in range(0, len(coordinates), 2):\n",
    "                # print(coordinates[c], coordinates[c+1])\n",
    "                radec = ephem.Equatorial(coordinates[c], coordinates[c + 1])\n",
    "                coordinates_radec.append([radec.ra, radec.dec])\n",
    "            coordinates_radec = numpy.rad2deg(numpy.array(coordinates_radec))\n",
    "\n",
    "        # print(coordinates2)\n",
    "\n",
    "        # print(coordinates_radec)\n",
    "\n",
    "        src_polygons.append(coordinates_radec)\n",
    "\n",
    "    return src_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    class Args:\n",
    "        def __init__(self):\n",
    "            self.dryrun = False\n",
    "            self.debug = False\n",
    "            self.checkimages = False\n",
    "            self.deadspace = 0.0\n",
    "            self.skywidth = 1.0\n",
    "            self.merge = None\n",
    "            self.n_threads = 1\n",
    "            self.distance = 0\n",
    "            self.calibrate = []\n",
    "            self.gain = []\n",
    "            self.center_coord = None\n",
    "            self.region_fn = \"/home/dmoore/stacks/ngc3395/ha.reg\"\n",
    "            self.output = \"/home/dmoore/PycharmProjects/AstroData/haflux.csv\"\n",
    "            self.files = [\n",
    "                \"/home/dmoore/stacks/ngc3395/ngc3395_ha.SIGMACLIPMEDIAN.fits\"\n",
    "            ]\n",
    "\n",
    "\n",
    "    args = Args()\n",
    "\n",
    "    logging.basicConfig(format='%(name)s -- %(levelname)s: %(message)s',\n",
    "                        level=logging.DEBUG if args.debug else logging.INFO)\n",
    "    logger = logging.getLogger(\"PolyFlux\")\n",
    "    logger.info(\"Sky parameters: %f // %f\" % (args.deadspace, args.skywidth))\n",
    "\n",
    "    # parse the calibration constants\n",
    "    calibration_factors = {}\n",
    "    print(args.calibrate)\n",
    "    for calib in args.calibrate:  # .split(\",\"):\n",
    "        items = calib.split(\":\")\n",
    "        if (len(items) == 2):\n",
    "            filtername = items[0]\n",
    "            factor = float(items[1])\n",
    "            calibration_factors[filtername] = factor\n",
    "\n",
    "    # parse the gain values\n",
    "    gain_values = {}\n",
    "    print(args.gain)\n",
    "    for calib in args.gain:  # .split(\",\"):\n",
    "        items = calib.split(\":\")\n",
    "        if (len(items) == 2):\n",
    "            filtername = items[0]\n",
    "            value, key = None, None\n",
    "            try:\n",
    "                value = float(items[1])\n",
    "            except:\n",
    "                key = items[1]\n",
    "            gain_values[filtername] = (value, key)\n",
    "\n",
    "    distance_cm = 1.0\n",
    "    if (args.distance > 0):\n",
    "        distance_cm = args.distance * 3.0857e24  # cm/Mpc\n",
    "        logger.info(\"Using distance of %.2f Mpc (%g cm)\" % (args.distance, distance_cm))\n",
    "\n",
    "    src_polygons = read_polygons_from_ds9_region_file(args.region_fn)\n",
    "    logger.info(\"Found %d source polygons\" % (len(src_polygons)))\n",
    "\n",
    "    center_pos = None\n",
    "    if (args.center_coord is not None):\n",
    "        center_pos = astropy.coordinates.SkyCoord(args.center_coord, unit=(u.hourangle, u.deg))\n",
    "    #\n",
    "    # Let's run the integration code on all files, one after another\n",
    "    #\n",
    "    master_catalog = None\n",
    "    for image_fn in args.files:\n",
    "\n",
    "        name, _ = os.path.splitext(image_fn)\n",
    "        if (image_fn.find(\":\") > 0):\n",
    "            items = image_fn.split(\":\")\n",
    "            if (len(items) == 2):\n",
    "                image_fn = items[0]\n",
    "                name = items[1]\n",
    "\n",
    "        logger.info(\"Working on image file %s (regions: %s // name: %s)\" % (image_fn, args.region_fn, name))\n",
    "        named_logger = logging.getLogger(name)\n",
    "\n",
    "        #\n",
    "        # Now lets read the image\n",
    "        #\n",
    "        named_logger.debug(\"Reading %s\" % (image_fn))\n",
    "        image_hdu = pyfits.open(image_fn)\n",
    "        # image_hdu.info()\n",
    "\n",
    "        image_data = image_hdu[0].data\n",
    "        wcs = astropy.wcs.WCS(image_hdu[0].header)\n",
    "\n",
    "        if (name not in gain_values):\n",
    "            gain = 1.\n",
    "        else:\n",
    "            (gain_value, gain_key) = gain_values[name]\n",
    "            if (gain_key is not None):\n",
    "                try:\n",
    "                    gain = image_hdu[0].header['GAIN']\n",
    "                    logger.info(\"Using GAIN = %.3f from header\" % (gain))\n",
    "                except:\n",
    "                    gain = 1000.\n",
    "                    logger.info(\"Using fall-back GAIN = %.3f\" % (gain))\n",
    "            else:\n",
    "                gain = gain_value\n",
    "\n",
    "        # print(wcs)\n",
    "\n",
    "        # photflam = image_hdu['SCI'].header['PHOTFLAM']\n",
    "        # photplam = image_hdu['SCI'].header['PHOTPLAM']\n",
    "        # zp_ab = -2.5*numpy.log10(photflam) - 5*numpy.log10(photplam) - 2.408\n",
    "        # print(\"ZP_AB = %f\" % (zp_ab))\n",
    "        # # see https://www.stsci.edu/hst/instrumentation/acs/data-analysis/zeropoints\n",
    "\n",
    "        # print(\"integrating sky polygons\")\n",
    "        # _, sky_data = measure_polygons(sky_polygons, image_data, wcs)\n",
    "        named_logger.info(\"integrating source polygons\")\n",
    "        src_data, check_hdulists = measure_polygons(src_polygons, image_data, wcs,\n",
    "                                                    deadspace=args.deadspace,\n",
    "                                                    skysize=args.skywidth,\n",
    "                                                    generate_check_images=True)\n",
    "\n",
    "        (check_sources, check_dead, check_sky, check_source_sky) = check_hdulists\n",
    "\n",
    "        if (args.checkimages):\n",
    "            pyfits.HDUList(check_sources).writeto(\"check_sources.fits\", overwrite=True)\n",
    "            pyfits.HDUList(check_dead).writeto(\"check_dead.fits\", overwrite=True)\n",
    "            pyfits.HDUList(check_sky).writeto(\"check_sky.fits\", overwrite=True)\n",
    "            pyfits.HDUList(check_source_sky).writeto(\"check_source_sky.fits\", overwrite=True)\n",
    "\n",
    "        # src_data.info()\n",
    "        # convert polygon center coordinates from native pixels to Ra/Dec\n",
    "        # src_data.info()\n",
    "        # print(src_data['center_x'].astype(numpy.float).to_numpy())\n",
    "        _ra, _dec = wcs.all_pix2world(src_data['center_x'].astype(numpy.float).to_numpy(),\n",
    "                                      src_data['center_y'].astype(numpy.float).to_numpy(), 1)\n",
    "        src_data['center_ra'] = _ra\n",
    "        src_data['center_dec'] = _dec\n",
    "        # print(radec)\n",
    "\n",
    "        # apply flux calibrations\n",
    "        calib_factor = 1.0\n",
    "        if (name in calibration_factors):\n",
    "            calib_factor = calibration_factors[name]\n",
    "            named_logger.info(\"Apply calibration factor: %g\" % (calib_factor))\n",
    "\n",
    "        sky_error = (src_data['src_area'] * src_data['sky_var']).astype(numpy.float).to_numpy()\n",
    "        src_error = gain * src_data['src_flux'].astype(numpy.float).to_numpy()\n",
    "        flx_error = numpy.fabs(src_error) + sky_error * gain ** 2\n",
    "        flx_error[flx_error < 0] = 1e30\n",
    "        # print(type(flx_error.to_numpy()))\n",
    "        src_data['src_flux_error'] = numpy.power(flx_error, 0.5) / gain\n",
    "\n",
    "        src_data['calib_flux'] = src_data['flux_bgsub'] * calib_factor\n",
    "        src_data['calib_flux_error'] = src_data['src_flux_error'] * calib_factor\n",
    "\n",
    "        if (args.debug):\n",
    "            print(src_data[['flux_bgsub', 'src_flux_error', 'sky_std', 'sky_var']].to_markdown())\n",
    "\n",
    "        # convert flux to luminosity (multiply with 4*pi*d^2)\n",
    "        named_logger.info(\"calculating luminosity from flux and distance\")\n",
    "        src_data['calib_luminosity'] = src_data['calib_flux'] * 4 * numpy.pi * distance_cm ** 2\n",
    "        src_data['calib_luminosity_error'] = src_data['calib_flux_error'] * 4 * numpy.pi * distance_cm ** 2\n",
    "\n",
    "        if (center_pos is not None):\n",
    "            src_skycoords = astropy.coordinates.SkyCoord(src_data['center_ra'], src_data['center_dec'], unit=u.deg)\n",
    "            distances = src_skycoords.separation(center_pos)\n",
    "            src_data['center_distance_deg'] = distances.deg\n",
    "            # print(distances)\n",
    "\n",
    "            if (args.distance is not None):\n",
    "                src_data['center_distance_kpc'] = numpy.arctan(distances.rad) * args.distance * 1000.\n",
    "\n",
    "        new_column_names = [\"%s_%s\" % (name, col) for col in src_data.columns]\n",
    "        column_translate = dict(zip(src_data.columns, new_column_names))\n",
    "        src_data.rename(columns=column_translate, inplace=True)\n",
    "        # src_data.info()\n",
    "\n",
    "        if (master_catalog is None):\n",
    "            master_catalog = src_data\n",
    "        else:\n",
    "            master_catalog = master_catalog.merge(src_data, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "        named_logger.info(\"done with image %s\" % (image_fn))\n",
    "\n",
    "    master_catalog.info()\n",
    "    logger.info(\"writing final catalog to %s\" % (args.output))\n",
    "    master_catalog.to_csv(args.output, index=False)\n",
    "    logger.info(\"all done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
